{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T01:46:15.471275Z",
     "start_time": "2022-05-06T01:46:15.370183Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# std\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import json\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "\n",
    "# datasets\n",
    "import STRING\n",
    "import MINT\n",
    "import bioGRID\n",
    "import HuRI\n",
    "import HI_II_14_src\n",
    "import IM24272_src\n",
    "import Lit_BM_13_src\n",
    "import Lit_NB_13_src\n",
    "\n",
    "# my lib\n",
    "import PPILinkPred as pred\n",
    "import helper as hr\n",
    "import genData_helper as helper\n",
    "import traversalHelper as tr\n",
    "\n",
    "class ns:\n",
    "    BRToRelat = tr.Helper.binary_to_relation\n",
    "    toDualBR = tr.Helper.to_dual_binary_relation\n",
    "    BRToNode = tr.Helper.binary_relation_to_node\n",
    "    arr_pStr = tr.Helper.list_to_pathStrs\n",
    "    pStr_arr = tr.Helper.pathStrs_to_list\n",
    "    br_str = tr.Helper.br_to_pathStr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Random PPI Samples from Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T11:37:13.699149Z",
     "start_time": "2021-04-29T11:37:12.691219Z"
    },
    "deletable": false,
    "editable": false,
    "hide_input": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# human dataset: HuRI\n",
    "# DataFrame standard: {nodeA, nodeB, type, score}\n",
    "# randomly 50% of the dataset 10 times, save into json\n",
    "\n",
    "import_funcs = [HuRI.parse_HuRI(root=\"../\")]\n",
    "names = ['HuRI']\n",
    "\n",
    "for n in range(len(names)):\n",
    "    df = import_funcs[n]\n",
    "    ppi = [list(arr) for arr in np.asarray(df[['nodeA', 'nodeB']])]\n",
    "    sampledPPIs = [rn.sample(ppi, int(len(ppi)*0.5)) for i in range(10)]\n",
    "    with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(names[n]), \"w\") as f:\n",
    "        f.write(json.dumps(sampledPPIs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-22T22:40:07.142367Z",
     "start_time": "2022-04-22T22:39:45.612842Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'IM24272' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# human dataset: IM-24272, Lit-BM-13 (binary & complex), HI-II-14\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# DataFrame standard: {nodeA, nodeB, type, score}\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# randomly 50% of the dataset 10 times, save into json\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m import_funcs \u001b[38;5;241m=\u001b[39m [\u001b[43mIM24272\u001b[49m\u001b[38;5;241m.\u001b[39mparse_IM24272(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      6\u001b[0m                 (Lit_BM_13\u001b[38;5;241m.\u001b[39mparse_Lit_BM_13(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../\u001b[39m\u001b[38;5;124m\"\u001b[39m))[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m      7\u001b[0m                 (Lit_BM_13\u001b[38;5;241m.\u001b[39mparse_Lit_BM_13(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../\u001b[39m\u001b[38;5;124m\"\u001b[39m))[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m      8\u001b[0m                 HI_II_14\u001b[38;5;241m.\u001b[39mparse_HI(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m      9\u001b[0m names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIM24272\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLit_13_binary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLit_13_cplx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHI_14\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(names)):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'IM24272' is not defined"
     ]
    }
   ],
   "source": [
    "# human dataset: IM-24272, Lit-BM-13 (binary & complex), HI-II-14\n",
    "# DataFrame standard: {nodeA, nodeB, type, score}\n",
    "# randomly 50% of the dataset 10 times, save into json\n",
    "\n",
    "import_funcs = [IM24272.parse_IM24272(root=\"../\"),\n",
    "                (Lit_BM_13.parse_Lit_BM_13(root=\"../\"))[0],\n",
    "                (Lit_BM_13.parse_Lit_BM_13(root=\"../\"))[1],\n",
    "                HI_II_14.parse_HI(root=\"../\")]\n",
    "names = ['IM24272', \"Lit_13_binary\", \"Lit_13_cplx\", \"HI_14\"]\n",
    "\n",
    "for n in range(len(names)):\n",
    "    df = import_funcs[n]\n",
    "    ppi = [list(arr) for arr in np.asarray(df[['nodeA', 'nodeB']])]\n",
    "    sampledPPIs = [rn.sample(ppi, int(len(ppi)*0.5)) for i in range(10)]\n",
    "    with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(names[n]), \"w\") as f:\n",
    "        f.write(json.dumps(sampledPPIs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T09:29:33.666848Z",
     "start_time": "2022-04-23T09:29:33.179057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14390 0\n",
      "5522 1\n",
      "2453 2\n",
      "6934 3\n"
     ]
    }
   ],
   "source": [
    "# human dataset direct source from L3\n",
    "# DataFrame standard: {nodeA, nodeB, type, score}\n",
    "# randomly 50% of the dataset 10 times, save into json\n",
    "\n",
    "import_funcs = [IM24272_src.parse_IM24272_src(root=\"../\"),\n",
    "                Lit_BM_13_src.parse_Lit_BM_src(root=\"../\"),\n",
    "                Lit_NB_13_src.parse_Lit_NB_src(root=\"../\"),\n",
    "                HI_II_14_src.parse_HI_src(root=\"../\")]\n",
    "names = ['IM24272_src', \"Lit_BM_src\", \"Lit_NB_src\", \"HI_14_src\"]\n",
    "\n",
    "for n in range(len(names)):\n",
    "    df = import_funcs[n]\n",
    "    ppi = [list(arr) for arr in np.asarray(df[['nodeA', 'nodeB']])]\n",
    "    sampledPPIs = [rn.sample(ppi, int(len(ppi)*0.5)) for i in range(10)]\n",
    "    with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(names[n]), \"w\") as f:\n",
    "        f.write(json.dumps(sampledPPIs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:25:02.153289Z",
     "start_time": "2021-05-14T07:24:51.285401Z"
    },
    "deletable": false,
    "editable": false,
    "hide_input": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# human dataset: HuRI\n",
    "# DataFrame standard: {nodeA, nodeB, type, score}\n",
    "# randomly 55-90% of the dataset 10 times, save into json\n",
    "\n",
    "import_funcs = [HuRI.parse_HuRI(root=\"../\")]\n",
    "names = ['HuRI']\n",
    "\n",
    "for randSz in range(95, 54, -5):\n",
    "    for n in range(len(names)):\n",
    "        df = import_funcs[n]\n",
    "        ppi = [list(arr) for arr in np.asarray(df[['nodeA', 'nodeB']])]\n",
    "        sampledPPIs = [rn.sample(ppi, int(len(ppi)*(randSz*0.01))) for i in range(10)]\n",
    "        with open(\"./sampled_datasets/{}_sampledPPIs_{}Percent.json\".format(names[n], randSz), \"w\") as f:\n",
    "            f.write(json.dumps(sampledPPIs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T11:37:31.255972Z",
     "start_time": "2021-04-29T11:37:13.701151Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# human datasets\n",
    "import_funcs = [\n",
    "    bioGRID.parse_bioGRID(filename='./data/BioGRID/BIOGRID-ORGANISM-Homo_sapiens-3.5.187.tab2.txt'\n",
    "        , wFile_GGI='./data/parsed/BioGRID_homo_GGI.pkl'\n",
    "        , wFile_PPI='./data/parsed/BioGRID_homo_PPI.pkl', root=\"../\")\n",
    "\n",
    "    , STRING.parse_STRING(ppiFile='./data/STRING/9606.protein.links.v11.0.txt'\n",
    "        , typeFile='./data/STRING/9606.protein.actions.v11.0.txt'\n",
    "        , uniProtMap='./data/UniProt/uniprot-taxonomy_9606_STRING.tab', root='../'\n",
    "        , wFile_GGI='./data/parsed/STRING_homo_GGI.pkl', wFile_PPI='./data/parsed/STRING_homo_PPI.pkl')\n",
    "\n",
    "    , MINT.parse_MINT(ppiFile='./data/MINT/species human', uniProtMap=\"./data/UniProt/uniprot-taxonomy_9606.tab\"\n",
    "        , wFile_GGI='./data/parsed/MINT_homo_GGI.pkl', wFile_PPI='./data/parsed/MINT_homo_PPI.pkl', root=\"../\")\n",
    "]\n",
    "names = ['bioGRID_human', \"STRING_human\", \"MINT_human\"]\n",
    "\n",
    "for n in range(len(names)):\n",
    "    _, df = import_funcs[n]\n",
    "    ppi = [list(arr) for arr in np.asarray(df[['nodeA', 'nodeB']])]\n",
    "    sampledPPIs = [rn.sample(ppi, int(len(ppi)*0.5)) for i in range(10)]\n",
    "    with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(names[n]), \"w\") as f:\n",
    "        f.write(json.dumps(sampledPPIs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T07:29:35.384163Z",
     "start_time": "2021-05-14T07:26:27.628592Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# human datasets\n",
    "import_funcs = [\n",
    "    bioGRID.parse_bioGRID(filename='./data/BioGRID/BIOGRID-ORGANISM-Homo_sapiens-3.5.187.tab2.txt'\n",
    "        , wFile_GGI='./data/parsed/BioGRID_homo_GGI.pkl'\n",
    "        , wFile_PPI='./data/parsed/BioGRID_homo_PPI.pkl', root=\"../\")\n",
    "\n",
    "    , STRING.parse_STRING(ppiFile='./data/STRING/9606.protein.links.v11.0.txt'\n",
    "        , typeFile='./data/STRING/9606.protein.actions.v11.0.txt'\n",
    "        , uniProtMap='./data/UniProt/uniprot-taxonomy_9606_STRING.tab', root='../'\n",
    "        , wFile_GGI='./data/parsed/STRING_homo_GGI.pkl', wFile_PPI='./data/parsed/STRING_homo_PPI.pkl')\n",
    "\n",
    "    , MINT.parse_MINT(ppiFile='./data/MINT/species human', uniProtMap=\"./data/UniProt/uniprot-taxonomy_9606.tab\"\n",
    "        , wFile_GGI='./data/parsed/MINT_homo_GGI.pkl', wFile_PPI='./data/parsed/MINT_homo_PPI.pkl', root=\"../\")\n",
    "]\n",
    "names = ['bioGRID_human', \"STRING_human\", \"MINT_human\"]\n",
    "\n",
    "for randSz in range(95, 54, -5):\n",
    "    for n in range(len(names)):\n",
    "        _, df = import_funcs[n]\n",
    "        ppi = [list(arr) for arr in np.asarray(df[['nodeA', 'nodeB']])]\n",
    "        sampledPPIs = [rn.sample(ppi, int(len(ppi)*(randSz*0.01))) for i in range(10)]\n",
    "        with open(\"./sampled_datasets/{}_sampledPPIs_{}Percent.json\".format(names[n], randSz), \"w\") as f:\n",
    "            f.write(json.dumps(sampledPPIs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T16:21:57.363558Z",
     "start_time": "2021-05-06T16:20:47.609083Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# human dataset\n",
    "# sample non-PPIs of real-PPIs size\n",
    "\n",
    "ds_names = ['bioGRID_human', 'STRING_human', 'MINT_human', 'HuRI']\n",
    "import_funcs = [\n",
    "    bioGRID.parse_bioGRID(filename='./data/BioGRID/BIOGRID-ORGANISM-Homo_sapiens-3.5.187.tab2.txt'\n",
    "        , wFile_GGI='./data/parsed/BioGRID_homo_GGI.pkl'\n",
    "        , wFile_PPI='./data/parsed/BioGRID_homo_PPI.pkl', root=\"../\")\n",
    "\n",
    "    , STRING.parse_STRING(ppiFile='./data/STRING/9606.protein.links.v11.0.txt'\n",
    "        , typeFile='./data/STRING/9606.protein.actions.v11.0.txt'\n",
    "        , uniProtMap='./data/UniProt/uniprot-taxonomy_9606_STRING.tab', root='../'\n",
    "        , wFile_GGI='./data/parsed/STRING_homo_GGI.pkl', wFile_PPI='./data/parsed/STRING_homo_PPI.pkl')\n",
    "\n",
    "    , MINT.parse_MINT(ppiFile='./data/MINT/species human', uniProtMap=\"./data/UniProt/uniprot-taxonomy_9606.tab\"\n",
    "        , wFile_GGI='./data/parsed/MINT_homo_GGI.pkl', wFile_PPI='./data/parsed/MINT_homo_PPI.pkl', root=\"../\")\n",
    "]\n",
    "completePPIs_map = [\n",
    "    [list(ppi) for ppi in np.asarray([*import_funcs[0]][1][['nodeA', 'nodeB']])]\n",
    "    , [list(ppi) for ppi in np.asarray([*import_funcs[1]][1][['nodeA', 'nodeB']])]\n",
    "    , [list(ppi) for ppi in np.asarray([*import_funcs[2]][1][['nodeA', 'nodeB']])]\n",
    "    , [list(ppi) for ppi in np.asarray(HuRI.parse_HuRI(root=\"../\")[['nodeA', 'nodeB']])]\n",
    "]\n",
    "ppi_ds = dict(zip(ds_names, completePPIs_map))\n",
    "\n",
    "for ds in ppi_ds:\n",
    "    ppi = ppi_ds[ds]\n",
    "    validNodes = list(ns.BRToNode(ppi))\n",
    "    ppi_str = set(ns.arr_pStr(ns.toDualBR(ppi)))\n",
    "    ppiNumDoub = len(validNodes)*len(validNodes)-1\n",
    "\n",
    "    sampled_nonPPIs = []\n",
    "    for i in range(10):\n",
    "        candidatePPIs = set()\n",
    "        while len(candidatePPIs) < len(ppi):\n",
    "            rnPPI_i = rn.randint(0, ppiNumDoub)\n",
    "            nodeA, nodeB = validNodes[math.floor(rnPPI_i/len(validNodes))], validNodes[rnPPI_i%len(validNodes)]\n",
    "            if nodeA == nodeB: continue\n",
    "            rnPPI = [nodeA, nodeB]\n",
    "            rnPPI_str, rnPPI_str_rev = ns.br_str(rnPPI), ns.br_str(rnPPI[::-1])\n",
    "            if rnPPI_str in ppi_str or rnPPI_str_rev in candidatePPIs or rnPPI_str in candidatePPIs: continue\n",
    "            candidatePPIs.add(rnPPI_str)\n",
    "        sampled_nonPPIs.append(ns.pStr_arr(list(candidatePPIs)))\n",
    "    \n",
    "    with open(\"./sampled_datasets/{}_sampled_nonPPIs.json\".format(ds), \"w\") as f:\n",
    "        f.write(json.dumps(sampled_nonPPIs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Link Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T13:40:24.885585Z",
     "start_time": "2021-05-01T03:48:18.938103Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "methods = [\"commonNeighbor\", \"L3Normalizing\", \"CRA\", \"CH2_L3\", \"Sim\", \"L3E1_f1\", \"L3E1_f2\"]\n",
    "ds_names = ['HuRI', 'MINT_human']\n",
    "\n",
    "for ds_name in ds_names:\n",
    "    # read dataset\n",
    "    samplePPIs = []\n",
    "    with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(ds_name), \"r\") as f:\n",
    "        samplePPIs = json.loads(f.read())\n",
    "\n",
    "    # do link prediction & save results\n",
    "    for method in methods:\n",
    "        for i in range(len(samplePPIs)):\n",
    "            saveFilename = \"{}_{}_sample_{}\".format(method, ds_name, i)\n",
    "            startTime = time.time()\n",
    "            \n",
    "            # jupyter notebook cannot display multi core logging, do it only in terminal\n",
    "            predPPI, predScore = pred.multiCore_PPILinkPred(samplePPIs[i]\n",
    "                                                            , method, coreNo=14, logging=False)\n",
    "            helper.write_runTime(saveFilename, time.time()-startTime)\n",
    "            helper.write_resultData(predPPI, predScore, saveFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-23T11:57:02.730077Z",
     "start_time": "2022-04-23T09:42:06.904366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#methods = ['commonNeighbor', 'L3Normalizing', 'L3E1_f1', 'L3E1_f2']\n",
    "methods = ['CRA']\n",
    "ds_names = ['IM24272_src', \"Lit_BM_src\", \"Lit_NB_src\", \"HI_14_src\"]\n",
    "\n",
    "for ds_name in ds_names:\n",
    "    # read dataset\n",
    "    samplePPIs = []\n",
    "    with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(ds_name), \"r\") as f:\n",
    "        samplePPIs = json.loads(f.read())\n",
    "\n",
    "    # do link prediction & save results\n",
    "    for method in methods:\n",
    "        for i in range(len(samplePPIs)):\n",
    "            saveFilename = \"{}_{}_sample_{}\".format(method, ds_name, i)\n",
    "            startTime = time.time()\n",
    "            \n",
    "            # jupyter notebook cannot display multi core logging, do it only in terminal\n",
    "            predPPI, predScore = pred.multiCore_PPILinkPred(samplePPIs[i]\n",
    "                                                            , method, coreNo=14, logging=False)\n",
    "            helper.write_runTime(saveFilename, time.time()-startTime)\n",
    "            helper.write_resultData(predPPI, predScore, saveFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "methods = [\"commonNeighbor\", \"L3Normalizing\", \"CRA\", \"Sim\", \"L3E1_f1\", 'L3E1_f2', 'random']\n",
    "# skip CH2 and L3E1_f2 first because waste time, may use HPC\n",
    "ds_names = ['HuRI', 'MINT_human']\n",
    "\n",
    "for randSz in range(60, 100, 10):\n",
    "    for ds_name in ds_names:\n",
    "        # read dataset\n",
    "        samplePPIs = []\n",
    "        with open(\"./sampled_datasets/{}_sampledPPIs_{}Percent.json\".format(ds_name, randSz), \"r\") as f:\n",
    "            samplePPIs = json.loads(f.read())\n",
    "\n",
    "        # do link prediction & save results\n",
    "        for method in methods:\n",
    "            print(randSz, ds_name, method)\n",
    "            for i in range(len(samplePPIs)):\n",
    "                saveFilename = \"{}_{}_sample_{}_randSz{}Percent\".format(method, ds_name, i, randSz)\n",
    "                startTime = time.time()\n",
    "\n",
    "                # jupyter notebook cannot display multi core logging, do it only in terminal\n",
    "                predPPI, predScore = pred.multiCore_PPILinkPred(samplePPIs[i]\n",
    "                                                                , method, coreNo=14, logging=False)\n",
    "                helper.write_runTime(saveFilename, time.time()-startTime)\n",
    "                helper.write_resultData(predPPI, predScore, saveFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-30T15:27:41.695646Z",
     "start_time": "2021-06-30T15:19:54.618632Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# randomly choose n edges, n = size of sampled dataset\n",
    "ds_names = ['bioGRID_human', 'STRING_human', 'MINT_human', 'HuRI']\n",
    "\n",
    "for randSz in range(50, 100, 10):\n",
    "    for ds_name in ds_names:\n",
    "        samplePPIs = []\n",
    "        if randSz == 50:\n",
    "            with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(ds_name), \"r\") as f:\n",
    "                samplePPIs = json.loads(f.read())\n",
    "        else:\n",
    "            with open(\"./sampled_datasets/{}_sampledPPIs_{}Percent.json\".format(ds_name, randSz), \"r\") as f:\n",
    "                samplePPIs = json.loads(f.read())\n",
    "        sampleSize = len(samplePPIs[0])\n",
    "        sampleSize = int(sampleSize/(randSz/100)*np.around(1-randSz/100, 2))\n",
    "\n",
    "        # loop each method, each trial, extract the number into one json\n",
    "        fullPPIs, fullScores = [], []\n",
    "        for trial in range(10):\n",
    "            samplePPIbr = samplePPIs[trial]\n",
    "            sampleNodes = list(ns.BRToNode(samplePPIbr))\n",
    "            samplePPIbr_str = set(ns.arr_pStr(ns.toDualBR(samplePPIbr)))\n",
    "            ppiNumDoub = len(sampleNodes)*len(sampleNodes)-1\n",
    "\n",
    "            candidatePPIs = set()\n",
    "            while len(candidatePPIs) < sampleSize:\n",
    "                rnPPI_i = rn.randint(0, ppiNumDoub)\n",
    "                nodeA, nodeB = sampleNodes[math.floor(rnPPI_i/len(sampleNodes))], sampleNodes[rnPPI_i%len(sampleNodes)]\n",
    "                if nodeA == nodeB: continue\n",
    "                rnPPI = [nodeA, nodeB]\n",
    "                rnPPI_str, rnPPI_str_rev = ns.br_str(rnPPI), ns.br_str(rnPPI[::-1])\n",
    "                if rnPPI_str in samplePPIbr_str or rnPPI_str_rev in candidatePPIs or rnPPI_str in candidatePPIs: continue\n",
    "                candidatePPIs.add(rnPPI_str)\n",
    "\n",
    "            fullPPIs.append(ns.pStr_arr(candidatePPIs))\n",
    "            fullScores.append([1 for i in range(sampleSize)])\n",
    "        \n",
    "        if randSz == 50:\n",
    "            with open(\"./linkPred_out_reduced/random_{}_topPPI.json\".format(ds_name), \"w\") as f:\n",
    "                f.write(json.dumps(fullPPIs))\n",
    "            with open(\"./linkPred_out_reduced/random_{}_topScore.json\".format(ds_name), \"w\") as f:\n",
    "                f.write(json.dumps(fullScores))\n",
    "        else:\n",
    "            with open(\"./linkPred_out_reduced/random_{}_randSz{}_topPPI.json\".format(ds_name, randSz), \"w\") as f:\n",
    "                f.write(json.dumps(fullPPIs))\n",
    "            with open(\"./linkPred_out_reduced/random_{}_randSz{}_topScore.json\".format(ds_name, randSz), \"w\") as f:\n",
    "                f.write(json.dumps(fullScores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bioGRID, STRING Human Dataset are generated using generate_prediction_HPC.py script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning for Analysis & Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T08:11:19.547376Z",
     "start_time": "2021-05-29T08:11:15.625847Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract only top n edges, n = size of sampled dataset\n",
    "methods = [\"commonNeighbor\", \"L3Normalizing\", \"CRA\", \"CH2_L3\", \"Sim\", \"L3E1_f1\", \"L3E1_f2\"]\n",
    "ds_names = ['bioGRID_human', 'STRING_human']\n",
    "\n",
    "for ds_name in ds_names:\n",
    "    sampleSize = 0\n",
    "    with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(ds_name), \"r\") as f:\n",
    "        sampleSize = len(json.loads(f.read())[0])\n",
    "    \n",
    "    # loop each method, each trial, extract the number into one json\n",
    "    for method in methods:\n",
    "        for trial in range(10):\n",
    "            topPPIs, topScores = [], []\n",
    "            for core in range(24):\n",
    "                with open(\"./linkPred_human_out/{}_{}_sample_{}_c{}_PPI.json\".format(method, ds_name, trial, core), \"r\") as f:\n",
    "                    topPPIs += json.loads(f.read())\n",
    "                with open(\"./linkPred_human_out/{}_{}_sample_{}_c{}_score.json\".format(method, ds_name, trial, core), \"r\") as f:\n",
    "                    topScores += json.loads(f.read())\n",
    "                topPPIs, topScores = hr.sort_key_val(topPPIs, topScores)\n",
    "                topPPIs, topScores = topPPIs[:sampleSize], topScores[:sampleSize]\n",
    "            \n",
    "            with open(\"./linkPred_human_out_combined/{}_{}_sample_{}_topPPI.json\".format(method, ds_name, trial), \"w\") as f:\n",
    "                f.write(json.dumps(topPPIs))\n",
    "            with open(\"./linkPred_human_out_combined/{}_{}_sample_{}_topScore.json\".format(method, ds_name, trial), \"w\") as f:\n",
    "                f.write(json.dumps(topScores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T20:25:34.810542Z",
     "start_time": "2021-08-29T18:55:28.576608Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract only top n edges, n = size of sampled dataset\n",
    "methods = [\"L3E_f1Alt\", \"L3E_f2Alt\"]\n",
    "ds_names = ['STRING_human']\n",
    "\n",
    "for ds_name in ds_names:\n",
    "    sampleSize = 0\n",
    "    with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(ds_name), \"r\") as f:\n",
    "        sampleSize = len(json.loads(f.read())[0])\n",
    "    \n",
    "    # loop each method, each trial, extract the number into one json\n",
    "    for method in methods:\n",
    "        for trial in range(10):\n",
    "            topPPIs, topScores = [], []\n",
    "            for core in range(12):\n",
    "                with open(\"E:/research/ppiLPred_BMC/notebook/linkPred_out/{}_{}_sample_{}_c{}_PPI.json\".format(method, ds_name, trial, core), \"r\") as f:\n",
    "                    topPPIs += json.loads(f.read())\n",
    "                with open(\"E:/research/ppiLPred_BMC/notebook/linkPred_out/{}_{}_sample_{}_c{}_score.json\".format(method, ds_name, trial, core), \"r\") as f:\n",
    "                    topScores += json.loads(f.read())\n",
    "                topPPIs, topScores = hr.sort_key_val(topPPIs, topScores)\n",
    "                topPPIs, topScores = topPPIs[:sampleSize], topScores[:sampleSize]\n",
    "            \n",
    "            with open(\"E:/research/ppiLPred_BMC/notebook/linkPred_out_combined/{}_{}_sample_{}_topPPI.json\".format(method, ds_name, trial), \"w\") as f:\n",
    "                f.write(json.dumps(topPPIs))\n",
    "            with open(\"E:/research/ppiLPred_BMC/notebook/linkPred_out_combined/{}_{}_sample_{}_topScore.json\".format(method, ds_name, trial), \"w\") as f:\n",
    "                f.write(json.dumps(topScores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-29T08:11:19.548376Z",
     "start_time": "2021-05-29T08:11:15.743Z"
    },
    "deletable": false,
    "editable": false,
    "hide_input": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "methods = [\"commonNeighbor\", \"L3Normalizing\", \"CRA\", \"CH2_L3\", \"Sim\", \"L3E1_f1\", \"L3E1_f2\"]\n",
    "ds_names = ['STRING_human', 'bioGRID_human']\n",
    "\n",
    "for ds_name in ds_names:\n",
    "    for method in methods:\n",
    "        fullPPIs, fullScores = [], []\n",
    "        for trial in range(10):\n",
    "            with open(\"./linkPred_human_out_combined/{}_{}_sample_{}_topPPI.json\".format(method, ds_name, trial), \"r\") as f:\n",
    "                fullPPIs.append(json.loads(f.read()))\n",
    "            with open(\"./linkPred_human_out_combined/{}_{}_sample_{}_topScore.json\".format(method, ds_name, trial), \"r\") as f:\n",
    "                fullScores.append(json.loads(f.read()))\n",
    "                \n",
    "        with open(\"./linkPred_human_out_reduced/{}_{}_topPPI.json\".format(method, ds_name), \"w\") as f:\n",
    "            f.write(json.dumps(fullPPIs))\n",
    "        with open(\"./linkPred_human_out_reduced/{}_{}_topScore.json\".format(method, ds_name), \"w\") as f:\n",
    "            f.write(json.dumps(fullScores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T20:27:51.839347Z",
     "start_time": "2021-08-29T20:27:23.334167Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "methods = [\"L3E_f1Alt\", \"L3E_f2Alt\"]\n",
    "ds_names = ['STRING_human', 'bioGRID_human']\n",
    "\n",
    "for ds_name in ds_names:\n",
    "    for method in methods:\n",
    "        fullPPIs, fullScores = [], []\n",
    "        for trial in range(10):\n",
    "            with open(\"E:/research/ppiLPred_BMC/notebook/linkPred_out_combined/{}_{}_sample_{}_topPPI.json\".format(method, ds_name, trial), \"r\") as f:\n",
    "                fullPPIs.append(json.loads(f.read()))\n",
    "            with open(\"E:/research/ppiLPred_BMC/notebook/linkPred_out_combined/{}_{}_sample_{}_topScore.json\".format(method, ds_name, trial), \"r\") as f:\n",
    "                fullScores.append(json.loads(f.read()))\n",
    "                \n",
    "        with open(\"./linkPred_out_reduced/{}_{}_topPPI.json\".format(method, ds_name), \"w\") as f:\n",
    "            f.write(json.dumps(fullPPIs))\n",
    "        with open(\"./linkPred_out_reduced/{}_{}_topScore.json\".format(method, ds_name), \"w\") as f:\n",
    "            f.write(json.dumps(fullScores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T19:36:00.203276Z",
     "start_time": "2021-05-01T16:24:34.002351Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# extract only top n edges, n = size of sampled dataset\n",
    "methods = [\"commonNeighbor\", \"L3Normalizing\", \"CRA\", \"CH2_L3\", \"L3E1_f1\", \"L3E1_f2\", \"Sim\"]\n",
    "ds_names = ['MINT_human', 'HuRI']\n",
    "\n",
    "for ds_name in ds_names:\n",
    "    samplePPIs = []\n",
    "    with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(ds_name), \"r\") as f:\n",
    "        samplePPIs = json.loads(f.read())\n",
    "    sampleSize = len(samplePPIs[0])\n",
    "    \n",
    "    # loop each method, each trial, extract the number into one json\n",
    "    for method in methods:\n",
    "        fullPPI, fullScore = [], []\n",
    "        for trial in range(10):\n",
    "            with open(\"./linkPred_human_out/{}_{}_sample_{}_PPI.json\".format(method, ds_name, trial), \"r\") as f:\n",
    "                fullPPI.append(json.loads(f.read())[0:sampleSize])\n",
    "            with open(\"./linkPred_human_out/{}_{}_sample_{}_score.json\".format(method, ds_name, trial), \"r\") as f:\n",
    "                fullScore.append(json.loads(f.read())[0:sampleSize])\n",
    "        with open(\"./linkPred_human_out_reduced/{}_{}_topPPI.json\".format(method, ds_name), \"w\") as f:\n",
    "            f.write(json.dumps(fullPPI))\n",
    "        with open(\"./linkPred_human_out_reduced/{}_{}_topScore.json\".format(method, ds_name), \"w\") as f:\n",
    "            f.write(json.dumps(fullScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T16:21:47.342079Z",
     "start_time": "2022-05-05T15:58:56.576992Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L3E1_f1Alt IM24272_src\n",
      "L3E1_f2Alt IM24272_src\n",
      "L3E1_f1Alt Lit_BM_src\n",
      "L3E1_f2Alt Lit_BM_src\n",
      "L3E1_f1Alt Lit_NB_src\n",
      "L3E1_f2Alt Lit_NB_src\n",
      "L3E1_f1Alt HI_14_src\n",
      "L3E1_f2Alt HI_14_src\n"
     ]
    }
   ],
   "source": [
    "# get full PPIs here\n",
    "methods = [\"L3E1_f1Alt\", \"L3E1_f2Alt\"]\n",
    "ds_names = ['IM24272_src', \"Lit_BM_src\", \"Lit_NB_src\", \"HI_14_src\"]\n",
    "\n",
    "for ds_name in ds_names:\n",
    "    samplePPIs = []\n",
    "    with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(ds_name), \"r\") as f:\n",
    "        samplePPIs = json.loads(f.read())\n",
    "    sampleSize = len(samplePPIs[0])\n",
    "    \n",
    "    # loop each method, each trial, extract the number into one json\n",
    "    for method in methods:\n",
    "        fullPPI, fullScore = [], []\n",
    "        print(method, ds_name)\n",
    "        #if os.path.exists(\"./linkPred_out_reduced/{}_{}_topPPI.json\".format(method, ds_name)): continue\n",
    "        for trial in range(10):\n",
    "            with open(\"./linkPred_out/{}_{}_sample_{}_PPI.json\".format(method, ds_name, trial), \"r\") as f:\n",
    "                fullPPI.append(json.loads(f.read()))\n",
    "            with open(\"./linkPred_out/{}_{}_sample_{}_score.json\".format(method, ds_name, trial), \"r\") as f:\n",
    "                fullScore.append(json.loads(f.read()))\n",
    "        with open(\"./linkPred_out_reduced/{}_{}_topPPI.json\".format(method, ds_name), \"w\") as f:\n",
    "            f.write(json.dumps(fullPPI))\n",
    "        with open(\"./linkPred_out_reduced/{}_{}_topScore.json\".format(method, ds_name), \"w\") as f:\n",
    "            f.write(json.dumps(fullScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-22T15:36:08.786790Z",
     "start_time": "2021-06-22T15:36:08.771784Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "allPaths = [\"I:/research/ppiLPred_BMC/notebook\"\n",
    "            , \"E:/research/ppiLPred_BMC/notebook\"\n",
    "            , \"D:/research offline repo/ppiLPred_BMC/notebook\"\n",
    "            , \"G:/research/ppiLPred_BMC/notebook\"]\n",
    "coreNo, trialNum = 12, 10\n",
    "def verify(method, ds, randSz):\n",
    "    # check HPC or not\n",
    "    isHPC = None\n",
    "    for path in allPaths:\n",
    "        # check if file exists in linkPred_out_reduced\n",
    "        if os.path.exists(\"./linkPred_out_reduced/{}_{}_randSz{}_topPPI.json\".format(\n",
    "            method, ds, randSz)): return 0, None, None\n",
    "        \n",
    "        if os.path.exists(\"{}/linkPred_out/{}_{}_sample_9_randSz{}Percent_c0_PPI.json\".format(\n",
    "            path, method, ds, randSz)):\n",
    "            isHPC = True\n",
    "            break\n",
    "        elif os.path.exists(\"{}/linkPred_out/{}_{}_sample_9_randSz{}Percent_PPI.json\".format(\n",
    "            path, method, ds, randSz)):\n",
    "            isHPC = False\n",
    "            break\n",
    "            \n",
    "    if isHPC is None: return 2, None, None\n",
    "    # iterate the abs path to all related files\n",
    "    filenames = []\n",
    "    if isHPC:\n",
    "        for trial in range(trialNum):\n",
    "            for core in range(coreNo):\n",
    "                for path in allPaths:\n",
    "                    filename = \"{}/linkPred_out/{}_{}_sample_{}_randSz{}Percent_c{}_PPI.json\".format(\n",
    "                        path, method, ds, trial, randSz, core)\n",
    "                    if os.path.exists(filename): filenames.append(filename.split(\"_PPI.json\")[0])\n",
    "    else:\n",
    "        for trial in range(trialNum):\n",
    "            for path in allPaths:\n",
    "                filename = \"{}/linkPred_out/{}_{}_sample_{}_randSz{}Percent_PPI.json\".format(\n",
    "                    path, method, ds, trial, randSz)\n",
    "                if os.path.exists(filename): filenames.append(filename.split(\"_PPI.json\")[0])\n",
    "    # return available, list of files, also isHPC\n",
    "    return 1, filenames, isHPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T08:37:58.247038Z",
     "start_time": "2021-05-30T05:50:28.681688Z"
    },
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 bioGRID_human commonNeighbor None 0\n",
      "50 bioGRID_human L3Normalizing None 0\n",
      "50 bioGRID_human CRA None 0\n",
      "50 bioGRID_human CH2_L3 None 0\n",
      "50 bioGRID_human Sim None 0\n",
      "50 bioGRID_human random None 0\n",
      "50 bioGRID_human L3E1_f1 None 0\n",
      "50 bioGRID_human L3E1_f2 None 0\n",
      "50 STRING_human commonNeighbor None 0\n",
      "50 STRING_human L3Normalizing None 0\n",
      "50 STRING_human CRA None 0\n",
      "50 STRING_human CH2_L3 True 1\n",
      "50 STRING_human Sim True 1\n",
      "50 STRING_human random None 0\n",
      "50 STRING_human L3E1_f1 True 1\n",
      "50 STRING_human L3E1_f2 True 1\n"
     ]
    }
   ],
   "source": [
    "allPaths = [\"I:/research/ppiLPred_BMC/notebook\"\n",
    "            , \"E:/research/ppiLPred_BMC/notebook\"\n",
    "            , \"D:/research offline repo/ppiLPred_BMC/notebook\"\n",
    "            , \"G:/research/ppiLPred_BMC/notebook\"]\n",
    "coreNo, trialNum = 24, 10\n",
    "def verify_tmp(method, ds):\n",
    "    for path in allPaths:\n",
    "        # check if file exists in linkPred_out_reduced\n",
    "        if os.path.exists(\"./linkPred_out_reduced/{}_{}_topPPI.json\".format(\n",
    "            method, ds)): return 0, None, None\n",
    "            \n",
    "    # iterate the abs path to all related files\n",
    "    filenames = []\n",
    "    for trial in range(trialNum):\n",
    "        for core in range(coreNo):\n",
    "            for path in allPaths:\n",
    "                filename = \"{}/linkPred_out/{}_{}_sample_{}_c{}_PPI.json\".format(\n",
    "                    path, method, ds, trial, core)\n",
    "                if os.path.exists(filename): filenames.append(filename.split(\"_PPI.json\")[0])\n",
    "    # return available, list of files, also isHPC\n",
    "    return 1, filenames, True\n",
    "\n",
    "# trim data that isn't trimmed yet\n",
    "methods = [\"commonNeighbor\", \"L3Normalizing\", \"CRA\", \"CH2_L3\", \"Sim\", 'random', \"L3E1_f1\", \"L3E1_f2\"]\n",
    "dss = ['bioGRID_human', 'STRING_human']\n",
    "coreNo, trialNum = 24, 10\n",
    "\n",
    "for ds in dss:\n",
    "    samplePPIs = []\n",
    "    with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(ds), \"r\") as f:\n",
    "        samplePPIs = json.loads(f.read())\n",
    "    sampleSize = len(samplePPIs[0])\n",
    "\n",
    "    for method in methods:\n",
    "        available, filenames, isHPC = verify_tmp(method, ds)\n",
    "        print(50, ds, method, isHPC, available)\n",
    "        if available != 1: continue\n",
    "            \n",
    "        for trial in range(trialNum):\n",
    "            topPPIs, topScores = [], []\n",
    "            for core in range(coreNo):\n",
    "                with open(filenames[trial*coreNo+core]+\"_PPI.json\", \"r\") as f: topPPIs += json.loads(f.read())\n",
    "                with open(filenames[trial*coreNo+core]+\"_score.json\", \"r\") as f: topScores += json.loads(f.read())\n",
    "                topPPIs, topScores = hr.sort_key_val(topPPIs, topScores)\n",
    "                topPPIs, topScores = topPPIs[:sampleSize], topScores[:sampleSize]\n",
    "            with open(\"./linkPred_out_combined/{}_{}_sample_{}_topPPI.json\".format(method, ds, trial), \"w\") as f:\n",
    "                f.write(json.dumps(topPPIs))\n",
    "            with open(\"./linkPred_out_combined/{}_{}_sample_{}_topScore.json\".format(method, ds, trial), \"w\") as f:\n",
    "                f.write(json.dumps(topScores))\n",
    "\n",
    "        fullPPIs, fullScores = [], []\n",
    "        for trial in range(10):\n",
    "            with open(\"./linkPred_out_combined/{}_{}_sample_{}_topPPI.json\".format(method, ds, trial), \"r\") as f:\n",
    "                fullPPIs.append(json.loads(f.read()))\n",
    "            with open(\"./linkPred_out_combined/{}_{}_sample_{}_topScore.json\".format(method, ds, trial), \"r\") as f:\n",
    "                fullScores.append(json.loads(f.read()))\n",
    "        with open(\"./linkPred_out_reduced/{}_{}_topPPI.json\".format(method, ds), \"w\") as f:\n",
    "            f.write(json.dumps(fullPPIs))\n",
    "        with open(\"./linkPred_out_reduced/{}_{}_topScore.json\".format(method, ds), \"w\") as f:\n",
    "            f.write(json.dumps(fullScores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:17:15.354100Z",
     "start_time": "2021-06-22T15:38:11.675766Z"
    },
    "hide_input": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 bioGRID_human L3E1_f2 True 1\n",
      "80 bioGRID_human CH2_L3 True 1\n",
      "80 STRING_human L3E1_f2 True 1\n",
      "80 STRING_human CH2_L3 True 1\n",
      "90 bioGRID_human L3E1_f2 True 1\n",
      "90 bioGRID_human CH2_L3 True 1\n",
      "90 STRING_human L3E1_f2 True 1\n",
      "90 STRING_human CH2_L3 True 1\n"
     ]
    }
   ],
   "source": [
    "# trim data that isn't trimmed yet\n",
    "methods = [\"L3E1_f2\", \"CH2_L3\"]\n",
    "dss = ['bioGRID_human', 'STRING_human']\n",
    "coreNo, trialNum = 24, 10\n",
    "\n",
    "# assume rawData complete\n",
    "def verify_tmp(method, ds, randSz):\n",
    "    for path in allPaths:\n",
    "        # check if file exists in linkPred_out_reduced\n",
    "        if os.path.exists(\"./linkPred_out_reduced/{}_{}_randSz{}_topPPI.json\".format(\n",
    "            method, ds, randSz)): return 0, None, None\n",
    "            \n",
    "    # iterate the abs path to all related files\n",
    "    filenames = []\n",
    "    for trial in range(trialNum):\n",
    "        for core in range(coreNo):\n",
    "            noFile = 0\n",
    "            for path in allPaths:\n",
    "                filename = \"{}/linkPred_out/{}_{}_sample_{}_randSz{}Percent_c{}_PPI.json\".format(\n",
    "                    path, method, ds, trial, randSz, core)\n",
    "                if os.path.exists(filename):\n",
    "                    filenames.append(filename.split(\"_PPI.json\")[0])\n",
    "                else:\n",
    "                    noFile += 1\n",
    "            if noFile == len(allPaths): break\n",
    "    # return available, list of files, also isHPC\n",
    "    return 1, filenames, True\n",
    "\n",
    "for randSz in range(80, 91, 10):\n",
    "    for ds in dss:\n",
    "        samplePPIs = []\n",
    "        with open(\"./sampled_datasets/{}_sampledPPIs_{}Percent.json\".format(ds, randSz), \"r\") as f:\n",
    "            samplePPIs = json.loads(f.read())\n",
    "        sampleSize = len(samplePPIs[0])\n",
    "        sampleSize = int(sampleSize/(randSz/100)*np.around(1-randSz/100, 2))\n",
    "\n",
    "        for method in methods:\n",
    "            available, filenames, isHPC = verify_tmp(method, ds, randSz)\n",
    "            print(randSz, ds, method, isHPC, available)\n",
    "            if available != 1: continue\n",
    "\n",
    "            for trial in range(trialNum):\n",
    "                topPPIs, topScores = [], []\n",
    "                relatedFiles = [file for file in filenames if \"sample_\"+str(trial) in file]\n",
    "                for file in relatedFiles:\n",
    "                    with open(file+\"_PPI.json\", \"r\") as f: topPPIs += json.loads(f.read())\n",
    "                    with open(file+\"_score.json\", \"r\") as f: topScores += json.loads(f.read())\n",
    "                    topPPIs, topScores = hr.sort_key_val(topPPIs, topScores)\n",
    "                    topPPIs, topScores = topPPIs[:sampleSize], topScores[:sampleSize]\n",
    "                with open(\"./linkPred_out_combined/{}_{}_sample_{}_randSz{}_topPPI.json\".format(method, ds, trial, randSz), \"w\") as f:\n",
    "                    f.write(json.dumps(topPPIs))\n",
    "                with open(\"./linkPred_out_combined/{}_{}_sample_{}_randSz{}_topScore.json\".format(method, ds, trial, randSz), \"w\") as f:\n",
    "                    f.write(json.dumps(topScores))\n",
    "\n",
    "            fullPPIs, fullScores = [], []\n",
    "            for trial in range(10):\n",
    "                with open(\"./linkPred_out_combined/{}_{}_sample_{}_randSz{}_topPPI.json\".format(method, ds, trial, randSz), \"r\") as f:\n",
    "                    fullPPIs.append(json.loads(f.read()))\n",
    "                with open(\"./linkPred_out_combined/{}_{}_sample_{}_randSz{}_topScore.json\".format(method, ds, trial, randSz), \"r\") as f:\n",
    "                    fullScores.append(json.loads(f.read()))\n",
    "            with open(\"./linkPred_out_reduced/{}_{}_randSz{}_topPPI.json\".format(method, ds, randSz), \"w\") as f:\n",
    "                f.write(json.dumps(fullPPIs))\n",
    "            with open(\"./linkPred_out_reduced/{}_{}_randSz{}_topScore.json\".format(method, ds, randSz), \"w\") as f:\n",
    "                f.write(json.dumps(fullScores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate GOSemSim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run **GOSemSim_compute.R** of the same directory, it scans ./linkPred_out and output GOSemSim in the same format of **xxx_topScore.json**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate precision recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:29:11.111040Z",
     "start_time": "2021-06-23T10:10:07.029755Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# for each dataset & predictor, get precision recall and save in one file for each trial\n",
    "methods = [\"commonNeighbor\", \"L3Normalizing\", \"CRA\", \"CH2_L3\", \"Sim\", \"L3E1_f1\", \"L3E1_f2\"]\n",
    "ds_names = ['bioGRID_human', 'STRING_human', 'MINT_human', 'HuRI']\n",
    "import_funcs = [\n",
    "    bioGRID.parse_bioGRID(filename='./data/BioGRID/BIOGRID-ORGANISM-Homo_sapiens-3.5.187.tab2.txt'\n",
    "        , wFile_GGI='./data/parsed/BioGRID_homo_GGI.pkl'\n",
    "        , wFile_PPI='./data/parsed/BioGRID_homo_PPI.pkl', root=\"../\")\n",
    "\n",
    "    , STRING.parse_STRING(ppiFile='./data/STRING/9606.protein.links.v11.0.txt'\n",
    "        , typeFile='./data/STRING/9606.protein.actions.v11.0.txt'\n",
    "        , uniProtMap='./data/UniProt/uniprot-taxonomy_9606_STRING.tab', root='../'\n",
    "        , wFile_GGI='./data/parsed/STRING_homo_GGI.pkl', wFile_PPI='./data/parsed/STRING_homo_PPI.pkl')\n",
    "\n",
    "    , MINT.parse_MINT(ppiFile='./data/MINT/species human', uniProtMap=\"./data/UniProt/uniprot-taxonomy_9606.tab\"\n",
    "        , wFile_GGI='./data/parsed/MINT_homo_GGI.pkl', wFile_PPI='./data/parsed/MINT_homo_PPI.pkl', root=\"../\")\n",
    "]\n",
    "completePPIs_map = [\n",
    "    [list(ppi) for ppi in np.asarray([*import_funcs[0]][1][['nodeA', 'nodeB']])]\n",
    "    , [list(ppi) for ppi in np.asarray([*import_funcs[1]][1][['nodeA', 'nodeB']])]\n",
    "    , [list(ppi) for ppi in np.asarray([*import_funcs[2]][1][['nodeA', 'nodeB']])]\n",
    "    , [list(ppi) for ppi in np.asarray(HuRI.parse_HuRI(root=\"../\")[['nodeA', 'nodeB']])]\n",
    "]\n",
    "completePPIs = dict(zip(ds_names, completePPIs_map))\n",
    "\n",
    "for randSz in range(50, 91, 10):\n",
    "    for ds_name in ds_names:\n",
    "        samplePPIs = []\n",
    "        if randSz != 50:\n",
    "            with open(\"./sampled_datasets/{}_sampledPPIs_{}Percent.json\".format(ds_name, randSz), \"r\") as f:\n",
    "                samplePPIs = json.loads(f.read())\n",
    "        else:\n",
    "            with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(ds_name), \"r\") as f:\n",
    "                samplePPIs = json.loads(f.read())\n",
    "\n",
    "\n",
    "        for method in methods:\n",
    "            fullPPIs = []\n",
    "            \n",
    "            if randSz != 50:\n",
    "                with open(\"./linkPred_out_reduced/{}_{}_randSz{}_topPPI.json\".format(method, ds_name, randSz), \"r\") as f:\n",
    "                    fullPPIs = json.loads(f.read())\n",
    "\n",
    "                # len(fullPPIs) = len(samplePPIs) = 10, because 10 trials\n",
    "                precRecMap = pred.precRecMap_multiCore(\n",
    "                    [\"{}_{}_randSz{}_topPPI_{}\".format(method, ds_name, randSz, i) for i in range(len(fullPPIs))]\n",
    "                  , fullPPIs, samplePPIs, [completePPIs[ds_name] for i in range(len(fullPPIs))]\n",
    "                  , coreNo=10)\n",
    "            else:\n",
    "                with open(\"./linkPred_out_reduced/{}_{}_topPPI.json\".format(method, ds_name), \"r\") as f:\n",
    "                    fullPPIs = json.loads(f.read())\n",
    "\n",
    "                # len(fullPPIs) = len(samplePPIs) = 10, because 10 trials\n",
    "                precRecMap = pred.precRecMap_multiCore(\n",
    "                    [\"{}_{}_topPPI_{}\".format(method, ds_name, i) for i in range(len(fullPPIs))]\n",
    "                  , fullPPIs, samplePPIs, [completePPIs[ds_name] for i in range(len(fullPPIs))]\n",
    "                  , coreNo=10)\n",
    "\n",
    "            for key in precRecMap:\n",
    "                with open(\"./precision_recall_out/{}.json\".format(key), 'w') as f:\n",
    "                    f.write(json.dumps(precRecMap[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T20:33:42.938584Z",
     "start_time": "2021-08-29T20:27:51.840348Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# for each dataset & predictor, get precision recall and save in one file for each trial\n",
    "methods = [\"L3E_f1Alt\", \"L3E_f2Alt\"]\n",
    "ds_names = ['bioGRID_human', 'STRING_human']\n",
    "import_funcs = [\n",
    "    bioGRID.parse_bioGRID(filename='./data/BioGRID/BIOGRID-ORGANISM-Homo_sapiens-3.5.187.tab2.txt'\n",
    "        , wFile_GGI='./data/parsed/BioGRID_homo_GGI.pkl'\n",
    "        , wFile_PPI='./data/parsed/BioGRID_homo_PPI.pkl', root=\"../\")\n",
    "\n",
    "    , STRING.parse_STRING(ppiFile='./data/STRING/9606.protein.links.v11.0.txt'\n",
    "        , typeFile='./data/STRING/9606.protein.actions.v11.0.txt'\n",
    "        , uniProtMap='./data/UniProt/uniprot-taxonomy_9606_STRING.tab', root='../'\n",
    "        , wFile_GGI='./data/parsed/STRING_homo_GGI.pkl', wFile_PPI='./data/parsed/STRING_homo_PPI.pkl')\n",
    "]\n",
    "completePPIs_map = [\n",
    "    [list(ppi) for ppi in np.asarray([*import_funcs[0]][1][['nodeA', 'nodeB']])]\n",
    "    , [list(ppi) for ppi in np.asarray([*import_funcs[1]][1][['nodeA', 'nodeB']])]\n",
    "]\n",
    "completePPIs = dict(zip(ds_names, completePPIs_map))\n",
    "\n",
    "for randSz in range(50, 51, 10):\n",
    "    for ds_name in ds_names:\n",
    "        samplePPIs = []\n",
    "        if randSz != 50:\n",
    "            with open(\"./sampled_datasets/{}_sampledPPIs_{}Percent.json\".format(ds_name, randSz), \"r\") as f:\n",
    "                samplePPIs = json.loads(f.read())\n",
    "        else:\n",
    "            with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(ds_name), \"r\") as f:\n",
    "                samplePPIs = json.loads(f.read())\n",
    "\n",
    "\n",
    "        for method in methods:\n",
    "            fullPPIs = []\n",
    "            \n",
    "            if randSz != 50:\n",
    "                with open(\"./linkPred_out_reduced/{}_{}_randSz{}_topPPI.json\".format(method, ds_name, randSz), \"r\") as f:\n",
    "                    fullPPIs = json.loads(f.read())\n",
    "\n",
    "                # len(fullPPIs) = len(samplePPIs) = 10, because 10 trials\n",
    "                precRecMap = pred.precRecMap_multiCore(\n",
    "                    [\"{}_{}_randSz{}_topPPI_{}\".format(method, ds_name, randSz, i) for i in range(len(fullPPIs))]\n",
    "                  , fullPPIs, samplePPIs, [completePPIs[ds_name] for i in range(len(fullPPIs))]\n",
    "                  , coreNo=10)\n",
    "            else:\n",
    "                with open(\"./linkPred_out_reduced/{}_{}_topPPI.json\".format(method, ds_name), \"r\") as f:\n",
    "                    fullPPIs = json.loads(f.read())\n",
    "\n",
    "                # len(fullPPIs) = len(samplePPIs) = 10, because 10 trials\n",
    "                precRecMap = pred.precRecMap_multiCore(\n",
    "                    [\"{}_{}_topPPI_{}\".format(method, ds_name, i) for i in range(len(fullPPIs))]\n",
    "                  , fullPPIs, samplePPIs, [completePPIs[ds_name] for i in range(len(fullPPIs))]\n",
    "                  , coreNo=10)\n",
    "\n",
    "            for key in precRecMap:\n",
    "                with open(\"./precision_recall_out/{}.json\".format(key), 'w') as f:\n",
    "                    f.write(json.dumps(precRecMap[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-23T12:37:37.189Z"
    }
   },
   "outputs": [],
   "source": [
    "# for each dataset & predictor, get precision recall and save in one file for each trial\n",
    "methods = ['commonNeighbor', 'L3Normalizing', 'L3E1_f1', 'L3E1_f2']\n",
    "ds_names = ['IM24272_src', \"Lit_BM_src\", \"Lit_NB_src\", \"HI_14_src\"]\n",
    "\n",
    "import_funcs = [IM24272_src.parse_IM24272_src(root=\"../\"),\n",
    "                Lit_BM_13_src.parse_Lit_BM_src(root=\"../\"),\n",
    "                Lit_NB_13_src.parse_Lit_NB_src(root=\"../\"),\n",
    "                HI_II_14_src.parse_HI_src(root=\"../\")]\n",
    "completePPIs_map = [\n",
    "    [list(arr) for arr in np.asarray(import_funcs[0][['nodeA', 'nodeB']])],\n",
    "    [list(arr) for arr in np.asarray(import_funcs[1][['nodeA', 'nodeB']])],\n",
    "    [list(arr) for arr in np.asarray(import_funcs[2][['nodeA', 'nodeB']])],\n",
    "    [list(arr) for arr in np.asarray(import_funcs[3][['nodeA', 'nodeB']])]\n",
    "]\n",
    "\n",
    "completePPIs = dict(zip(ds_names, completePPIs_map))\n",
    "\n",
    "for ds_name in ds_names:\n",
    "    samplePPIs = []\n",
    "    with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(ds_name), \"r\") as f:\n",
    "        samplePPIs = json.loads(f.read())\n",
    "\n",
    "\n",
    "    for method in methods:\n",
    "        fullPPIs = []\n",
    "\n",
    "        with open(\"./linkPred_out_reduced/{}_{}_topPPI.json\".format(method, ds_name), \"r\") as f:\n",
    "            fullPPIs = json.loads(f.read())\n",
    "\n",
    "        # len(fullPPIs) = len(samplePPIs) = 10, because 10 trials\n",
    "        precRecMap = pred.precRecMap_multiCore(\n",
    "            [\"{}_{}_topPPI_{}\".format(method, ds_name, i) for i in range(len(fullPPIs))]\n",
    "          , fullPPIs, samplePPIs, [completePPIs[ds_name] for i in range(len(fullPPIs))]\n",
    "          , coreNo=5)\n",
    "\n",
    "        for key in precRecMap:\n",
    "            with open(\"./precision_recall_out/{}.json\".format(key), 'w') as f:\n",
    "                f.write(json.dumps(precRecMap[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T01:55:33.611218Z",
     "start_time": "2022-05-06T01:46:25.310093Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dynamic PR generate, to 10% recall\n",
    "# for each dataset & predictor, get precision recall and save in one file for each trial\n",
    "methods = ['L3E1_f1Alt', 'L3E1_f2Alt']\n",
    "ds_names = ['IM24272_src', \"Lit_BM_src\", \"Lit_NB_src\", \"HI_14_src\"]\n",
    "\n",
    "import_funcs = [IM24272_src.parse_IM24272_src(root=\"../\"),\n",
    "                Lit_BM_13_src.parse_Lit_BM_src(root=\"../\"),\n",
    "                Lit_NB_13_src.parse_Lit_NB_src(root=\"../\"),\n",
    "                HI_II_14_src.parse_HI_src(root=\"../\")]\n",
    "import_funcs = dict(zip(ds_names, import_funcs))\n",
    "\n",
    "for ds_name in ds_names:\n",
    "    samplePPIs = []\n",
    "    with open(\"./sampled_datasets/{}_sampledPPIs.json\".format(ds_name), \"r\") as f:\n",
    "        samplePPIs = json.loads(f.read())\n",
    "    completePPIs = [list(arr) for arr in np.asarray(import_funcs[ds_name][['nodeA', 'nodeB']])]\n",
    "    for method in methods:\n",
    "        topPPIs = []\n",
    "        for trial in range(10):\n",
    "            with open(\"./linkPred_out/{}_{}_sample_{}_PPI.json\".format(method, ds_name, trial), \"r\") as f:\n",
    "                topPPIs = json.loads(f.read())\n",
    "            prCurve = {\"prec\": [], \"rec\": []}\n",
    "            tpPPICnt = 0\n",
    "            PPIToHit = set(ns.arr_pStr(completePPIs))-set(ns.arr_pStr(ns.toDualBR(samplePPIs[trial])))\n",
    "            truePPICnt = len(PPIToHit)\n",
    "            for i in range(len(topPPIs)):\n",
    "                if ns.br_str(topPPIs[i]) in PPIToHit or ns.br_str(topPPIs[i][::-1]) in PPIToHit:\n",
    "                    tpPPICnt += 1\n",
    "                prCurve['prec'].append(tpPPICnt/(i+1))\n",
    "                prCurve['rec'].append(tpPPICnt/truePPICnt)\n",
    "                if (tpPPICnt/truePPICnt) >= 0.1: break\n",
    "            with open(\"./precision_recall_out/{}_{}_topPPI_{}.json\".format(\n",
    "                method, ds_name, trial), 'w') as f:\n",
    "                f.write(json.dumps(prCurve))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}